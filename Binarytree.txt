4321,
Binarytree,
In computer science, a binary tree is a k-ary 
k
=
2
{\displaystyle k=2}
 tree data structure in which each node has at most two children, which are referred to as the left child and the right child.  A recursive definition using just set theory notions is that a (non-empty) binary tree is a tuple (L, S, R), where L and R are binary trees or the empty set and S is a singleton set containing the root.[1] Some authors allow the binary tree to be the empty set as well.[2]
From a graph theory perspective, binary (and K-ary) trees as defined here are arborescences.[3] A binary tree may thus be also called a bifurcating arborescence[3]—a term which appears in some very old programming books,[4] before the modern computer science terminology prevailed. It is also possible to interpret a binary tree as an undirected, rather than a directed graph, in which case a binary tree is an ordered, rooted tree.[5] Some authors use rooted binary tree instead of binary tree to emphasize the fact that the tree is rooted, but as defined above, a binary tree is always rooted.[6] A binary tree is a special case of an ordered K-ary tree, where K is 2.
In mathematics, what is termed binary tree can vary significantly from author to author. Some use the definition commonly used in computer science,[7] but others define it as every non-leaf having exactly two children and don't necessarily order (as left/right) the children either.[8]
In computing, binary trees can be used in two very different ways:
To define a binary tree, the possibility that only one of the children may be empty must be acknowledged. An artifact, which in some textbooks is called an extended binary tree, is needed for that purpose. An extended binary tree is thus recursively defined as:[11]
Another way of imagining this construction (and understanding the terminology) is to consider instead of the empty set a different type of node—for instance square nodes if the regular ones are circles.[12]
A binary tree is a rooted tree that is also an ordered tree (a.k.a. plane tree) in which every node has at most two children. A rooted tree naturally imparts a notion of levels (distance from the root), thus for every node a notion of children may be defined as the nodes connected to it a level below. Ordering of these children (e.g., by drawing them on a plane) makes it possible to distinguish a left child from a right child.[13] But this still doesn't distinguish between a node with left but not a right child from a one with right but no left child.
The necessary distinction can be made by first partitioning the edges, i.e., defining the binary tree as triplet (V, E1, E2), where (V, E1 ∪ E2) is a rooted tree (equivalently arborescence) and E1 ∩ E2 is empty, and also requiring that for all j ∈ { 1, 2 } every node has at most one Ej child.[14] A more informal way of making the distinction is to say, quoting the Encyclopedia of Mathematics, that "every node has a left child, a right child, neither, or both" and to specify that these "are all different" binary trees.[7]
Tree terminology is not well-standardized and so varies in literatures.
In combinatorics one considers the problem of counting the number of full binary trees of a given size.  Here the trees have no values attached to their nodes (this would just multiply the number of possible trees by an easily determined factor), and trees are distinguished only by their structure; however, the left and right child of any node are distinguished (if they are different trees, then interchanging them will produce a tree distinct from the original one). The size of the tree is taken to be the number n of internal nodes (those with two children); the other nodes are leaf nodes and there are n + 1 of them. The number of such binary trees of size n is equal to the number of ways of fully parenthesizing a string of n + 1 symbols (representing leaves) separated by n binary operators (representing internal nodes), to determine the argument subexpressions of each operator. For instance for n = 3 one has to parenthesize a string like 
X
∗
X
∗
X
∗
X
{\displaystyle X*X*X*X}
, which is possible in five ways:
The correspondence to binary trees should be obvious, and the addition of redundant parentheses (around an already parenthesized expression or around the full expression) is disallowed (or at least not counted as producing a new possibility).
There is a unique binary tree of size 0 (consisting of a single leaf), and any other binary tree is characterized by the pair of its left and right children; if these have sizes i and j respectively, the full tree has size i + j + 1. Therefore, the number 
C
n
{\displaystyle C_{n}}
 of binary trees of size n has the following recursive description 
C
0
=
1
{\displaystyle C_{0}=1}
, and 
C
n
=
∑
i
=
0
n
−
1
C
i
C
n
−
1
−
i
{\displaystyle \textstyle C_{n}=\sum _{i=0}^{n-1}C_{i}C_{n-1-i}}
 for any positive integer n. It follows that 
C
n
{\displaystyle C_{n}}
 is the Catalan number of index n.
The above parenthesized strings should not be confused with the set of words of length 2n in the Dyck language, which consist only of parentheses in such a way that they are properly balanced. The number of such strings satisfies the same recursive description (each Dyck word of length 2n is determined by the Dyck subword enclosed by the initial '(' and its matching ')' together with the Dyck subword remaining after that closing parenthesis, whose lengths 2i and 2j satisfy i + j + 1 = n); this number is therefore also the Catalan number 
C
n
{\displaystyle C_{n}}
. So there are also five Dyck words of length 6:
These Dyck words do not correspond to binary trees in the same way. Instead, they are related by the following recursively defined bijection: the Dyck word equal to the empty string corresponds to the binary tree of size 0 with only one leaf. Any other Dyck word can be written as (
w
1
{\displaystyle w_{1}}
)
w
2
{\displaystyle w_{2}}
, where 
w
1
{\displaystyle w_{1}}
,
w
2
{\displaystyle w_{2}}
 are themselves (possibly empty) Dyck words and where the two written parentheses are matched. The bijection is then defined by letting the words 
w
1
{\displaystyle w_{1}}
 and 
w
2
{\displaystyle w_{2}}
 correspond to the binary trees that are the left and right children of the root.
A bijective correspondence can also be defined as follows: enclose the Dyck word in an extra pair of parentheses, so that the result can be interpreted as a Lisp list expression (with the empty list () as only occurring atom); then the dotted-pair expression for that proper list is a fully parenthesized expression (with NIL as symbol and '.' as operator) describing the corresponding binary tree (which is, in fact, the internal representation of the proper list).
The ability to represent binary trees as strings of symbols and parentheses implies that binary trees can represent the elements of a free magma on a singleton set.
Binary trees can be constructed from programming language primitives in several ways.
In a language with records and references, binary trees are typically constructed by having a tree node structure which contains some data and references to its left child and its right child. Sometimes it also contains a reference to its unique parent. If a node has fewer than two children, some of the child pointers may be set to a special null value, or to a special sentinel node.
This method of storing binary trees wastes a fair bit of memory, as the pointers will be null (or point to the sentinel) more than half the time; a more conservative representation alternative is threaded binary tree.[26]
In languages with tagged unions such as ML, a tree node is often a tagged union of two types of nodes, one of which is a 3-tuple of data, left child, and right child, and the other of which is a "leaf" node, which contains no data and functions much like the null value in a language with pointers. For example, the following line of code in OCaml (an ML dialect) defines a binary tree that stores a character in each node.[27]
Binary trees can also be stored in breadth-first order as an implicit data structure in arrays, and if the tree is a complete binary tree, this method wastes no space. In this compact arrangement, if a node has an index i, its children are found at indices 
2
i
+
1
{\displaystyle 2i+1}
 (for the left child) and 
2
i
+
2
{\displaystyle 2i+2}
 (for the right), while its parent (if any) is found at index 
⌊
i
−
1
2
⌋
{\displaystyle \left\lfloor {\frac {i-1}{2}}\right\rfloor }
 (assuming the root has index zero). Alternatively, with a 1-indexed array, the implementation is simplified with children found at 
2
i
{\displaystyle 2i}
 and 
2
i
+
1
{\displaystyle 2i+1}
, and parent found at 
⌊
i
/
2
⌋
{\displaystyle \lfloor i/2\rfloor }
.[28] This method benefits from more compact storage and better locality of reference, particularly during a preorder traversal. However, it is expensive to grow[29] and wastes space proportional[citation needed] to 2h - n for a tree of depth h with n nodes.
This method of storage is often used for binary heaps.[citation needed]
A succinct data structure is one which occupies close to minimum possible space, as established by information theoretical lower bounds. The number of different binary trees on 
n
{\displaystyle n}
 nodes is 
C
n
{\displaystyle \mathrm {C} _{n}}
, the 
n
{\displaystyle n}
th Catalan number (assuming we view trees with identical structure as identical). For large 
n
{\displaystyle n}
, this is about 
4
n
{\displaystyle 4^{n}}
; thus we need at least about 
log
2
⁡
4
n
=
2
n
{\displaystyle \log _{2}4^{n}=2n}
 bits to encode it. A succinct binary tree therefore would occupy 
2
n
+
o
(
n
)
{\displaystyle 2n+o(n)}
 bits.
One simple representation which meets this bound is to visit the nodes of the tree in preorder, outputting "1" for an internal node and "0" for a leaf.[30] If the tree contains data, we can simply simultaneously store it in a consecutive array in preorder. This function accomplishes this:
The string structure has only 
2
n
+
1
{\displaystyle 2n+1}
 bits in the end, where 
n
{\displaystyle n}
 is the number of (internal) nodes; we don't even have to store its length. To show that no information is lost, we can convert the output back to the original tree like this:
More sophisticated succinct representations allow not only compact storage of trees but even useful operations on those trees directly while they're still in their succinct form.
There is a one-to-one mapping between general ordered trees and binary trees, which in particular is used by Lisp to represent general ordered trees as binary trees. To convert a general ordered tree to a binary tree, we only need to represent the general tree in left-child right-sibling way. The result of this representation will automatically be a binary tree if viewed from a different perspective. Each node N in the ordered tree corresponds to a node N'  in the binary tree; the left child of N'  is the node corresponding to the first child of N, and the right child of N'  is the node corresponding to N's next sibling --- that is, the next node in order among the children of the parent of N. This binary tree representation of a general order tree is sometimes also referred to as a left-child right-sibling binary tree (also known as LCRS tree, doubly chained tree, filial-heir chain).
One way of thinking about this is that each node's children are in a linked list, chained together with their right fields, and the node only has a pointer to the beginning or head of this list, through its left field.
For example, in the tree on the left, A has the 6 children {B,C,D,E,F,G}.  It can be converted into the binary tree on the right.
The binary tree can be thought of as the original tree tilted sideways, with the black left edges representing first child and the blue right edges representing next sibling.  The leaves of the tree on the left would be written in Lisp as:
which would be implemented in memory as the binary tree on the right, without any letters on those nodes that have a left child.
There are a variety of different operations that can be performed on binary trees. Some are mutator operations, while others simply return useful information about the tree.
Nodes can be inserted into binary trees in between two other nodes or added after a leaf node. In binary trees, a node that is inserted is specified as to whose child it will be.
To add a new node after leaf node A, A assigns the new node as one of its children and the new node assigns node A as its parent.
Insertion on internal nodes is slightly more complex than on leaf nodes. Say that the internal node is node A and that node B is the child of A. (If the insertion is to insert a right child, then B is the right child of A, and similarly with a left child insertion.) A assigns its child to the new node and the new node assigns its parent to A. Then the new node assigns its child to B and B assigns its parent as the new node.
Deletion is the process whereby a node is removed from the tree.  Only certain nodes in a binary tree can be removed unambiguously.[31]
Suppose that the node to delete is node A. If A has no children, deletion is accomplished by setting the child of A's parent to null. If A has one child, set the parent of A's child to A's parent and set the child of A's parent to A's child.
In a binary tree, a node with two children cannot be deleted unambiguously.[31] However, in certain binary trees (including binary search trees) these nodes can be deleted, though with a rearrangement of the tree structure.
Pre-order, in-order, and post-order traversal visit each node in a tree by recursively visiting each node in the left and right subtrees of the root. Below are the brief descriptions of above mentioned traversals.
In pre-order we always visit the current node, next we recursively traverse the current node's left subtree and then we recursively traverse the current node's right subtree. The pre-order traversal is a topologically sorted one, because a parent node is processed before any of its child nodes is done.
In in-order we always recursively traverse the current node's left subtree, next we visit the current node and lastly we recursively traverse the current node's right subtree
In post-order we always recursively traverse the current node's left subtree, next we recursively traverse the current node's right subtree and then visit the current node. Post-order traversal can be useful to get postfix expression of a binary expression tree.[32]In depth-first order, we always attempt to visit the node farthest from the root node that we can, but with the caveat that it must be a child of a node we have already visited. Unlike a depth-first search on graphs, there is no need to remember all the nodes we have visited, because a tree cannot contain cycles. Pre-order is a special case of this. See depth-first search for more information.
Contrasting with depth-first order is breadth-first order, which always attempts to visit the node closest to the root that it has not already visited. See breadth-first search for more information. Also called a level-order traversal.
In a complete binary tree, a node's breadth-index (i − (2d − 1)) can be used as traversal instructions from the root. Reading bitwise from left to right, starting at bit d − 1, where d is the node's distance from the root (d = ⌊log2(i+1)⌋) and the node in question is not the root itself (d > 0). When the breadth-index is masked at bit d − 1, the bit values 0 and 1 mean to step either left or right, respectively. The process continues by successively checking the next bit to the right until there are no more. The rightmost bit indicates the final traversal from the desired node's parent to the node itself. There is a time-space trade-off between iterating a complete binary tree this way versus each node having pointer/s to its sibling/s.
