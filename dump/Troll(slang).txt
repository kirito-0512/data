14594,
Troll(slang),

In slang, a troll is a person who posts or makes inflammatory, insincere, digressive,[1] extraneous, or off-topic messages online (such as in social media, a newsgroup, a forum, a chat room, an online video game) or in real life, with the intent of provoking others into displaying emotional responses,[2] or manipulating others' perception, thus acting as a bully or a provocateur. The behavior is typically for the troll's amusement, or to achieve a specific result such as disrupting a rival's online activities or purposefully causing confusion or harm to other people.[3]
In this context, both the noun and the verb forms of "troll" are frequently associated with Internet discourse. Media attention in recent years has equated trolling with online harassment. The Courier-Mail and The Today Show have used "troll" to mean "a person who defaces Internet tribute sites with the aim of causing grief to families".[4][5] In addition, depictions of trolling have been included in popular fictional works, such as the HBO television program The Newsroom, in which a main character encounters harassing persons online and tries to infiltrate their circles by posting negative sexual comments.[6]
Application of the term troll is subjective. Some readers may characterize a post as trolling, while others may regard the same post as a legitimate contribution to the discussion, even if controversial.[7] More potent acts of trolling are blatant harassment or off-topic banter.[8] However, the term Internet troll has also been applied to information warfare, hate speech, and even political activism.[9][10]
The "Trollface" is an image occasionally used to indicate trolling in Internet culture.[11][12][13]
At times, the word is incorrectly used to refer to anyone with controversial, or differing, opinions.[14] Such usage goes against the ordinary meaning of troll in multiple ways. While psychologists have determined that psychopathological sadism, dark triad, and dark tetrad personality traits are common among Internet trolls,[15][16][17][18][19] some observers claim that trolls do not actually believe the controversial views they claim. Farhad Manjoo criticises this view, noting that if the person really is trolling, they are more intelligent than their critics would believe.[14]
The most common advice to deal with someone who gets enjoyment out of provoking others is to ignore them and deprive them of the pleasure of watching people react. This is typically phrased as "don't feed the trolls", however, some believe this to be bad or incomplete advice for effectively dealing with trolls.[20]
There are competing theories of where and when "troll" was first used in Internet slang, with numerous unattested accounts of BBS and Usenet origins in the early 1980s or before.[21]
The English noun "troll" in the standard sense of ugly dwarf or giant dates to 1610 and originates from the Old Norse word "troll" meaning giant or demon.[22] The word evokes the trolls of Scandinavian folklore and children's tales: antisocial, quarrelsome and slow-witted creatures which make life difficult for travelers.[23][24] Trolls have existed in folklore and fantasy literature for centuries, and online trolling has been around for as long as the Internet has existed.[25]
In modern English usage, "trolling" may describe the fishing technique of slowly dragging a lure or baited hook from a moving boat,[26] whereas trawling describes the generally commercial act of dragging a fishing net. Early non-Internet slang use of "trolling" can be found in the military: by 1972 the term "trolling for MiGs" was documented in use by US Navy pilots in Vietnam. It referred to use of "...decoys, with the mission of drawing...fire away..."[27]The contemporary use of the term is said to have appeared on the Internet in the late 1980s,[28][29] but the earliest known attestation according to the Oxford English Dictionary is in 1992.[30][31][32]
The context of the quote cited in the Oxford English Dictionary[31] sets the origin in Usenet in the early 1990s as in the phrase "trolling for newbies", as used in alt.folklore.urban (AFU).[33][34] Commonly, what is meant is a relatively gentle inside joke by veteran users, presenting questions or topics that had been so overdone that only a new user would respond to them earnestly. For example, a veteran of the group might make a post on the common misconception that glass flows over time. Long-time readers would both recognize the poster's name and know that the topic had been discussed repeatedly, but new subscribers to the group would not realize, and would thus respond. These types of trolls served as a practice to identify group insiders. This definition of trolling, considerably narrower than the modern understanding of the term, was considered a positive contribution.[33][35] One of the most notorious AFU trollers, David Mikkelson,[33] went on to create the urban folklore website Snopes.com.
By the late 1990s, alt.folklore.urban had such heavy traffic and participation that trolling of this sort was frowned upon. Others expanded the term to include the practice of playing a seriously misinformed user, even in newsgroups where one was not a regular; these were often attempts at humor rather than provocation. The noun troll usually referred to an act of trolling – or to the resulting discussion – rather than to the author, though some posts punned on the dual meaning of troll.[36]
The August 26, 1997 strip of webcomic Kevin and Kell used the word troll to describe those that deliberately harass or provoke other Internet users, similar to the modern sense of the word.[37]
In Chinese, trolling is referred to as bái mù (Chinese: 白目; lit. 'white eye'), which can be straightforwardly explained as "eyes without pupils", in the sense that while the pupil of the eye is used for vision, the white section of the eye cannot see, and trolling involves blindly talking nonsense over the Internet, having total disregard to sensitivities or being oblivious to the situation at hand, akin to having eyes without pupils. An alternative term is bái làn (Chinese: 白爛; lit. 'white rot'), which describes a post completely nonsensical and full of folly made to upset others, and derives from a Taiwanese slang term for the male genitalia, where genitalia that is pale white in color represents that someone is young, and thus foolish. Both terms originate from Taiwan, and are also used in Hong Kong and mainland China. Another term, xiǎo bái (Chinese: 小白; lit. 'little white') is a derogatory term for both bái mù and bái làn that is used on anonymous posting Internet forums. Another common term for a troll used in mainland China is pēn zi (Chinese: 噴子; lit. 'sprayer, spurter').[38]
In Japanese, tsuri (釣り) means "fishing" and refers to intentionally misleading posts whose only purpose is to get the readers to react, i.e. get trolled. Arashi (荒らし) means "laying waste" and can also be used to refer to simple spamming.
In Icelandic, þurs (a thurs) or tröll (a troll) may refer to trolls, the verbs þursa (to troll) or þursast (to be trolling, to troll about) may be used.[39][failed verification]
In Korean, nak-si (낚시) means "fishing" and refers to Internet trolling attempts, as well as purposely misleading post titles. A person who recognizes the troll after having responded (or, in case of a post title, nak-si, having read the actual post) would often refer to themselves as a caught fish.[40]
In Portuguese, more commonly in its Brazilian variant, troll (pronounced [ˈtɾɔw] in most of Brazil as spelling pronunciation) is the usual term to denote Internet trolls (examples of common derivate terms are trollismo or trollagem, "trolling", and the verb trollar, "to troll", which entered popular use), but an older expression, used by those which want to avoid anglicisms or slangs, is complexo do pombo enxadrista to denote trolling behavior, and pombos enxadristas (literally, "chessplayer pigeons") or simply pombos are the terms used to name the trolls. The terms are explained by an adage or popular saying: "Arguing with fulano (i.e., John Doe) is the same as playing chess with a pigeon: it defecates on the table, drops the pieces and simply flies off, claiming victory."
In Thai, the term krian (เกรียน) has been adopted to address Internet trolls. According to the Royal Institute of Thailand, the term, which literally refers to a closely cropped hairstyle worn by schoolboys in Thailand, is from the behaviour of these schoolboys who usually gather to play online games and, during which, make annoying, disruptive, impolite, or unreasonable expressions.[41]
Early incidents of trolling[42] were considered to be the same as flaming, but this has changed with modern usage by the news media to refer to the creation of any content that targets another person. The Internet dictionary, NetLingo, suggests there are four grades of trolling: playtime trolling, tactical trolling, strategic trolling, and domination trolling. The relationship between trolling and flaming was observed in open-access forums in California, on a series of modem-linked computers. CommuniTree was begun in 1978 but was closed in 1982 when accessed by high school teenagers, becoming a ground for trashing and abuse.[43]
Some psychologists have suggested that flaming would be caused by deindividuation or decreased self-evaluation: the anonymity of online postings would lead to disinhibition amongst individuals.[44] Others have suggested that although flaming and trolling is often unpleasant, it may be a form of normative behavior that expresses the social identity of a certain user group.[45][46] According to Tom Postmes, a professor of social and organisational psychology at the universities of Exeter, England, and Groningen, The Netherlands, and the author of Individuality and the Group, who has studied online behavior for 20 years, "Trolls aspire to violence, to the level of trouble they can cause in an environment. They want it to kick off. They want to promote antipathetic emotions of disgust and outrage, which morbidly gives them a sense of pleasure."[43] Someone who brings something off topic into the conversation in order to make that person mad is trolling.[47]
The practice of trolling has been documented by a number of academics since the 1990s. This included Steven Johnson in 1997 in the book Interface Culture, and a paper by Judith Donath in 1999. Donath's paper outlines the ambiguity of identity in a disembodied "virtual community" such as Usenet:
In the physical world there is an inherent unity to the self, for the body provides a compelling and convenient definition of identity. The norm is: one body, one identity ... The virtual world is different. It is composed of information rather than matter.[48]Donath provides a concise overview of identity deception games which trade on the confusion between physical and epistemic community:
Trolling is a game about identity deception, albeit one that is played without the consent of most of the players. The troll attempts to pass as a legitimate participant, sharing the group's common interests and concerns; the newsgroup's or forum's members, if they are cognizant of trolls and other identity deceptions, attempt to both distinguish real from trolling postings, and upon judging a poster a troll, make the offending poster leave the group. Their success at the former depends on how well they – and the troll – understand identity cues; their success at the latter depends on whether the troll's enjoyment is sufficiently diminished or outweighed by the costs imposed by the group.Whitney Phillips observes in This is Why We Can't Have Nice Things: Mapping the Relationship Between Online Trolling and Mainstream Culture that certain behaviors are consistent among different types of trolls. First, trolls of the subcultural variety self-identify as trolls.[49] Trolls are also motivated by what is known as lulz, a type of unsympathetic, ambiguous laughter. The final behavior is the insistent need for anonymity. According to Phillips, anonymity allows trolls to engage in behaviors they would not replicate in professional or public settings, with the effectiveness of trolling often being dependent upon the target's lack of anonymity. This can include the disclosure of real-life attachments, interests, and vulnerabilities of the target.
A troll can disrupt the discussion on a newsgroup or online forum, disseminate bad advice, and damage the feeling of trust in the online community. In a group that has become sensitized to trolling – where the rate of deception is high – many honestly naïve questions may be quickly rejected as trolling. This can be quite off-putting to the new user who upon first posting is immediately bombarded with angry accusations. Even if the accusations are unfounded, being branded a troll may be damaging to one's online reputation.[48]
Susan Herring and colleagues, in "Searching for Safety Online: Managing 'Trolling' in a Feminist Forum", point out the difficulty inherent in monitoring trolling and maintaining freedom of speech in online communities: "harassment often arises in spaces known for their freedom, lack of censure, and experimental nature".[50] Free speech may lead to tolerance of trolling behavior, complicating the members' efforts to maintain an open, yet supportive discussion area, especially for sensitive topics such as race, gender, and sexuality.[50]
Cyberbullying laws vary by state, as trolling is not a crime under U.S. federal law.[51] In an effort to reduce uncivil behavior by increasing accountability, many web sites (e.g. Reuters, Facebook, and Gizmodo) now require commenters to register their names and e-mail addresses.[52]
Trolling itself has become its own form of Internet subculture and has developed its own set of rituals, rules, specialized language, and dedicated spaces of practice.[53] The appeal of trolling primarily comes from the thrill of how long one can keep the ruse going before getting caught, and exposed as a troll. When understood this way, Internet trolls are less like vulgar, indiscriminate bullies, and closer to countercultural respondents to a (so called) overly sensitive public.
The main elements of why people troll are interactions; trolling exists in the interactive communications between Internet users, influencing people's views both from objective and emotional standpoints. Further, trolling does not target a single individual, but rather targets multiple members of a discussion. Trolling can  be easily identified by its offensive content, intended to provoke an emotional reaction from an audience.[53]
Organizations and countries may utilize trolls to manipulate public opinion as part and parcel of an astroturfing initiative. When trolling is sponsored by the government, it is often called state-sponsored Internet propaganda or state-sponsored trolling. Teams of sponsored trolls are sometimes referred to as sockpuppet armies.[54]
A 2016 study by Harvard political scientist Gary King reported that the Chinese government's 50 Cent Party creates 440 million pro-government social media posts per year.[55][56] The report said that government employees were paid to create pro-government posts around the time of national holidays to avoid mass political protests. The Chinese Government ran an editorial in the state-funded Global Times defending censorship and 50 Cent Party trolls.[55]
A 2016 study for the NATO Strategic Communications Centre of Excellence on hybrid warfare notes that the Russo-Ukrainian War "demonstrated how fake identities and accounts were used to disseminate narratives through social media, blogs, and web commentaries in order to manipulate, harass, or deceive opponents."[57]: 3  The NATO report describes that a "Wikipedia troll" uses a type of message design where a troll does not add "emotional value" to reliable "essentially true" information in re-posts, but presents it "in the wrong context, intending the audience to draw false conclusions." For example, information, without context, from Wikipedia about the military history of the United States "becomes value-laden if it is posted in the comment section of an article criticizing Russia for its military actions and interests in Ukraine. The Wikipedia troll is 'tricky', because in terms of actual text, the information is true, but the way it is expressed gives it a completely different meaning to its readers."[57]: 62 
Unlike "classic trolls," Wikipedia trolls "have no emotional input, they just supply misinformation" and are one of "the most dangerous" as well as one of "the most effective trolling message designs."[57]: 70, 76  Even among people who are "emotionally immune to aggressive messages" and apolitical, "training in critical thinking" is needed, according to the NATO report, because "they have relatively blind trust in Wikipedia sources and are not able to filter information that comes from platforms they consider authoritative."[57]: 72  While Russian-language hybrid trolls use the Wikipedia troll message design to promote anti-Western sentiment in comments, they "mostly attack aggressively to maintain emotional attachment to issues covered in articles."[57]: 75  Discussions about topics other than international sanctions during the Ukrainian crisis "attracted very aggressive trolling" and became polarized, according to the NATO report, which "suggests that in subjects in which there is little potential for re-educating audiences, emotional harm is considered more effective" for pro-Russian Latvian-language trolls.[57]: 76 
A 2016 study on fluoridation decision-making in Israel coined the term "Uncertainty Bias" to describe the efforts of power in government, public health and media to aggressively advance agendas by misrepresentation of historical and scientific fact. The authors noted that authorities tended to overlook or to deny situations that involve uncertainty while making unscientific arguments and disparaging comments in order to undermine opposing positions.[58]
The New York Times reported in late October 2018 that Saudi Arabia used an online army of Twitter trolls to harass the late Saudi dissident journalist Jamal Khashoggi and other critics of the Saudi government.[59]
In October 2018, The Daily Telegraph reported that Facebook "banned hundreds of pages and accounts which it says were fraudulently flooding its site with partisan political content – although they came from the US instead of being associated with Russia."[60]
While corporate networking site LinkedIn is considered a platform of good taste and professionalism, companies searching for personal information by promoting jobs that were not real and fake accounts posting political messages has caught the company off guard.[61]
Researcher Ben Radford wrote about the phenomenon of clowns in history and the modern day in his book Bad Clowns, and found that "bad clowns" have evolved into Internet trolls.[62] They do not dress up as traditional clowns but, for their own amusement, they tease and exploit "human foibles" in order to speak the "truth" and gain a reaction.[62] Like clowns in make-up, Internet trolls hide behind "anonymous accounts and fake usernames".[62] In their eyes, they are the trickster and are performing for a nameless audience via the Internet.[62] Studies conducted in the fields of human–computer interaction and cyberpsychology by other researchers have corroborated Radford's analysis on the phenomenon of Internet trolling as a form of deception-serving entertainment and its correlations to aggressive behaviour, katagelasticism, black humor, and the Dark tetrad.[15][16][17]
Trolling correlates positively with sadism,[16][17][18][19] trait psychopathy,[16][17][18][19] and Machiavellianism[63] (see Dark triad). Trolls take pleasure from causing pain and emotional suffering.[16][18][19] Their ability to upset or harm gives them a feeling of power.[63][64] Psychological researches conducted in the fields of personality psychology and cyberpsychology report that trolling behaviour qualifies as an anti-social behaviour and is strongly correlated to sadistic personality disorder (SPD).[16][18][19] Researches have shown that men, compared with women, are more likely to perpetrate trolling behaviour; these gender differences in online anti-social behaviour may be a reflection of gender stereotypes, where agentic characteristics such as competitiveness and dominance are encouraged in men.[19][65] The results corroborated that gender (male) is a significant predictor of trolling behaviour, alongside trait psychopathy and sadism to be significant positive predictors.[19] Moreover, these studies have shown that people who enjoy trolling online tend to also enjoy hurting other people in everyday life, therefore corroborating a longstanding and persistent pattern of psychopathological sadism.[18]
A psychoanalytic and sexologic study on the phenomenon of Internet trolling asserts that anonymity increases the incidence of the trolling behaviour, and that "the internet is becoming a medium to invest our anxieties and not thinking about the repercussions of trolling and affecting the victims mentally and incite a sense of guilt and shame within them".[66]
Concern trolls pretend to be sympathetic to a certain point of view which they are actually critical of. A concern troll will often declare an interest in joining or allying with a certain cause, while subtly ridiculing it.[67] The concern troll posts in web forums devoted to their declared point of view and attempts to sway the group's actions or opinions while claiming to share their goals, but with professed "concerns". The goal is to sow fear, uncertainty, and doubt within the group, sometimes by appealing to outrage culture.[68]
For example, a person who wishes to shame obese people, but disguises this impulse as concern for the health of overweight people, could be considered a concern troll.[69]
A verifiable example of concern trolling within politics occurred in 2006 when Tad Furtado, a member of staff for then-Congressman Charles Bass (R-N.H.), was caught posing as a "concerned" supporter of Bass's opponent, Democrat Paul Hodes, on several liberal New Hampshire blogs, using the pseudonyms "IndieNH" or "IndyNH". "IndyNH" expressed concern that Democrats might just be wasting their time or money on Hodes, because Bass was unbeatable.[70][71] Hodes eventually won the election.[72]
Although the term "concern troll" originated in discussions of online behavior, it now sees increasing use to describe similar offline behaviors. For example, James Wolcott of Vanity Fair accused a conservative New York Daily News columnist of "concern troll" behavior in his efforts to downplay the Mark Foley scandal. Wolcott links what he calls concern trolls to what Saul Alinsky calls "Do-Nothings", giving a long quote from Alinsky on the Do-Nothings' method and effects:
These Do-Nothings profess a commitment to social change for ideals of justice, equality, and opportunity, and then abstain from and discourage all effective action for change. They are known by their brand, 'I agree with your ends but not your means'.[73]The Hill published an op-ed piece by Markos Moulitsas of the liberal blog Daily Kos titled "Dems: Ignore 'Concern Trolls'". The concern trolls in question were not Internet participants but rather Republicans offering public advice and warnings to the Democrats that could be considered deceptive.[74]
The online forum TOTSE, as created in 1997, is considered one of the earliest trolling communities, predating 4chan by several years.[75] A New York Times article discussed troll activity at 4chan and at Encyclopedia Dramatica, which it described as "an online compendium of troll humor and troll lore".[28] 4chan's /b/ board is recognized as "one of the Internet's most infamous and active trolling hotspots".[76] This site and others are often used as a base to troll against sites that their members can not normally post on. These trolls feed off the reactions of their victims because "their agenda is to take delight in causing trouble".[77] Places like Reddit, 4chan, and other anonymous message boards are prime real-estate for online trolls. Because there's no easy way of tracing who someone is, trolls can post very inflammatory content without repercussion.[25]
The online French group Ligue du LOL has been accused of organized harassment and described as a troll group.[78]
Mainstream media outlets have focused their attention on the willingness of some Internet users to go to extreme lengths to participate in organized psychological harassment.
In February 2010, the Australian government became involved after users defaced the Facebook tribute pages of murdered children Trinity Bates and Elliott Fletcher. Australian communications minister Stephen Conroy decried the attacks, committed mainly by 4chan users, as evidence of the need for greater Internet regulation, stating, "This argument that the Internet is some mystical creation that no laws should apply to, that is a recipe for anarchy and the wild west."[79] Facebook responded by strongly urging administrators to be aware of ways to ban users and remove inappropriate content from Facebook pages.[80] In 2012, the Daily Telegraph started a campaign to take action against "Twitter trolls", who abuse and threaten users. Several high-profile Australians including Charlotte Dawson, Robbie Farah, Laura Dundovic, and Ray Hadley have been victims of this phenomenon.[81][82][83]
Bollywood culture merged with online communities in the late 1990s.[84] Consequently, Internet trolls took advantage of the online space to share political beliefs in the form of trolling. For example, the Maharashtra Legislative Assembly banned all cattle slaughter in India.[85] provoking the viral hashtag "#BeefBan" amongst Bollywood celebrities participating in hashtag activism. In 2015, Salman Khan participated in Internet activism regarding the death sentence of convict Yakub Memon. In response, Internet trolls harassed Bollywood celebrities that voiced right-winged opinions and labelled them as traitors.[84]Newslaundry covered the phenomenon of "Twitter trolling" in its "Criticles",[86] also characterizing Twitter trolls in its weekly podcasts.[87]
In July 2022, Japanese law banned "online insults," punishable by up to one year of imprisonment. Under this law, an "insult" is defined as "publicly demeaning someone's social standing without referring to specific facts about them or a specific action."[88][89]
In the United Kingdom, contributions made to the Internet are covered by the Malicious Communications Act 1988 as well as Section 127 of the Communications Act 2003, under which jail sentences were, until 2015, limited to a maximum of six months.[90] In October 2014, the UK's Justice Secretary, Chris Grayling, said that "Internet trolls" would face up to two years in jail, under measures in the Criminal Justice and Courts Bill that extend the maximum sentence and time limits for bringing prosecutions.[90][91] The House of Lords Select Committee on Communications had earlier recommended against creating a specific offence of trolling. Sending messages which are "grossly offensive or of an indecent, obscene or menacing character" is an offence whether they are received by the intended recipient or not. Several people have been imprisoned in the UK for online harassment.[92]
Trolls of the testimonial page of Georgia Varley faced no prosecution due to misunderstandings of the legal system in the wake of the term trolling being popularized.[93] In October 2012, a twenty-year-old man was jailed for twelve weeks for posting offensive jokes to a support group for friends and family of April Jones.[94]
On 31 March 2010, NBC's Today ran a segment detailing the deaths of three separate adolescent girls and trolls' subsequent reactions to their deaths. Shortly after the suicide of high school student Alexis Pilkington, anonymous posters began performing organized psychological harassment across various message boards, referring to Pilkington as a "suicidal slut", and posting graphic images on her Facebook memorial page. The segment also included an exposé of a 2006 accident, in which an eighteen-year-old fatally crashed her father's car into a highway pylon; trolls emailed her grieving family the leaked pictures of her mutilated corpse (see Nikki Catsouras photographs controversy).[5]
In 2007, the media was fooled by trollers into believing that students were consuming a drug called Jenkem, purportedly made of human waste. A user named Pickwick on TOTSE posted pictures implying that he was inhaling this drug. Major news corporations such as Fox News Channel reported the story and urged parents to warn their children about this drug. Pickwick's pictures of Jenkem were fake and the pictures did not actually feature human waste.[95]
In August 2012, the subject of trolling was featured on the HBO television series The Newsroom. The character Neal Sampat encounters harassing individuals online, particularly looking at 4chan, and he ends up choosing to post negative comments himself on an economics-related forum. The attempt by the character to infiltrate trolls' inner circles attracted debate from media reviewers critiquing the series.[96][97]
In 2019, it was alleged that progressive Democrats had created a fake Facebook page which mis-represented the political stance of Roy Moore, a Republican candidate, in the attempt to alienate him from pro-business Republicans. It was also alleged that a "false flag" experiment attempted to link Moore to the use of Russian Twitter bots.[98] The New York Times, when exposing the scam, quoted a New Knowledge report that boasted of its fabrications: "We orchestrated an elaborate 'false flag' operation that planted the idea that the [Roy] Moore campaign was amplified on social media by a Russian botnet.'"[99]
The 2020 Democratic presidential candidate Bernie Sanders has faced criticism for the behavior of some of his supporters online, but has deflected such criticism, suggesting that "Russians" were impersonating people claiming to be "Bernie Bro" supporters.[100] Twitter rejected Sanders' suggestion that Russia could be responsible for the bad reputation of his supporters. A Twitter spokesperson told CNBC: "Using technology and human review in concert, we proactively monitor Twitter to identify attempts at platform manipulation and mitigate them. As is standard, if we have reasonable evidence of state-backed information operations, we'll disclose them following our thorough investigation to our public archive — the largest of its kind in the industry."[101] Twitter had suspended 70 troll accounts that posted content in support of Michael Bloomberg's presidential campaign.[102]
The 45th American president, Donald J. Trump, infamously used Twitter to denigrate his political opponents and spread misinformation for which he earned the moniker Troll-In-Chief.[103]
So-called Gold Membership trolling originated in 2007 on 4chan boards, when users posted fake images claiming to offer upgraded 4chan account privileges; without a "Gold" account, one could not view certain content. This turned out to be a hoax designed to fool board members, especially newcomers. It was copied and became an Internet meme. In some cases, this type of troll has been used as a scam, most notably on Facebook, where fake Facebook Gold Account upgrade ads have proliferated in order to link users to dubious websites and other content.[104]
The case of Zeran v. America Online, Inc. resulted primarily from trolling. Six days after the Oklahoma City bombing, anonymous users posted advertisements for shirts celebrating the bombing on AOL message boards, claiming that the shirts could be obtained by contacting Mr. Kenneth Zeran. The posts listed Zeran's address and home phone number. Zeran was subsequently harassed.[105]
Anti-scientology protests by Anonymous, commonly known as Project Chanology, are sometimes labeled as "trolling" by media such as Wired,[106] and the participants sometimes explicitly self-identify as "trolls".
Neo-Nazi website The Daily Stormer orchestrates what it calls a "Troll Army", and has encouraged trolling of Jewish MP Luciana Berger and Muslim activist Mariam Veiszadeh.[107]
In 2012, after feminist Anita Sarkeesian started a Kickstarter campaign to fund a series of YouTube videos chronicling misogyny in video games, she received bomb threats at speaking engagements, doxxing threats, rape threats and an unwanted starring role in a video game called Beat Up Anita Sarkeesian.[108]
In 2018, the Russian government was accused of using sockpuppet armies consisting of 13 Russians and about three Russian companies including Concord Management to alter the outcome of the 2016 US presidential election.[109] With the aim of ensuring Republican Candidate, Donald Trump emerges victorious, the sockpuppets allegedly pushed various criminal conspiracies, political rallies, and disparaging comments about Trump major opponent, Hillary Clinton on social media.[109] Initially, only Twitter and Facebook detected the campaign but other reports suggest that YouTube, Tumblr, Google+, PayPal, and Instagram were used.[110] Donald Trump denied plotting with the Russian government to run the propaganda and the Russian Government vehemently denied ties to the companies indicted.
In 2020, the official Discord server and Twitch channel for the U.S. Army Esports team became a target of trolling, as people sent anti-U.S. Army messages, memes, and references to war crimes committed by the United States to both.[111] When the team started banning users from their Twitch channel for trolling, they were accused of violating the First Amendment to the United States Constitution by the ACLU and Knight First Amendment Institute at Columbia University.[112][113] The team has since denied these allegations.[114]
In 2021, the Salon columnist Amanda Marcotte, author of Troll Nation: How the Right Became Trump-Worshipping Monsters Set on Rat-F*cking Liberals, America, and Truth Itself (2018), described the American far-right exclusively male organization Proud Boys, the conservative pundit Tucker Carlson, and podcast host Joe Rogan as political commentators who have mastered "the art of trolling as a far-right recruitment strategy" by preying upon the American male insecurities, mediocrity, and fragility.[115] In particular, regarding their respective discriminatory comments about transgender people, she remarks "how crucial gender anxiety is to far-right recruitment".[115]


