27647,
Starheightproblem,
The star height problem in formal language theory is the question whether all regular languages can be expressed using regular expressions of limited star height, i.e. with a limited nesting depth of Kleene stars. Specifically, is a nesting depth of one always sufficient? If not, is there an algorithm to determine how many are required? The problem was raised by Eggan (1963).
The first question was answered in the negative when in 1963, Eggan gave examples of regular languages of star height n for every n. Here, the star height h(L) of a regular language L is defined as the minimum star height among all regular expressions representing L. The first few languages found by Eggan (1963) are described in the following, by means of giving a regular expression for each language:
The construction principle for these expressions is that expression 




e

n
+
1




{\displaystyle e_{n+1}}

 is obtained by concatenating two copies of 




e

n




{\displaystyle e_{n}}

, appropriately renaming the letters of the second copy using fresh alphabet symbols, concatenating the result with another fresh alphabet symbol, and then by surrounding the resulting expression with a Kleene star. The remaining, more difficult part, is to prove that for 




e

n




{\displaystyle e_{n}}

 there is no equivalent regular expression of star height less than n; a proof is given in (Eggan 1963).
However, Eggan's examples use a large alphabet, of size 2n-1 for the language with star height n. He thus asked whether we can also find examples over binary alphabets. This was proved to be true shortly afterwards by Dejean & Schützenberger (1966). 
Their examples can be described by an inductively defined family of regular expressions over the binary alphabet 



{
a
,
b
}


{\displaystyle \{a,b\}}

 as follows–cf. Salomaa (1981):
Again, a rigorous proof is needed for the fact that 




e

n




{\displaystyle e_{n}}

 does not admit an equivalent regular expression of lower star height. Proofs are given by (Dejean & Schützenberger 1966) and by (Salomaa 1981).
In contrast, the second question turned out to be much more difficult, and the question became a famous open problem in formal language theory for over two decades (Brzozowski 1980). For years, there was only little progress. The pure-group languages were the first interesting family of regular languages for which the star height problem was proved to be decidable (McNaughton 1967). But the general problem remained open for more than 25 years until it was settled by Hashiguchi, who in 1988 published an algorithm to determine the star height of any regular language. The algorithm wasn't at all practical, being of non-elementary complexity. To illustrate the immense resource consumptions of that algorithm, Lombardy and Sakarovitch (2002) give some actual numbers:
[The procedure described by Hashiguchi] leads to computations that are by far impossible, even for very small examples. For instance, if L is accepted by a 4 state automaton of loop complexity 3 (and with a small 10 element transition monoid), then a very low minorant of the number of languages to be tested with L for equality is:






(

10


10

10




)




(

10


10

10




)



(

10


10

10




)





.


{\displaystyle \left(10^{10^{10}}\right)^{\left(10^{10^{10}}\right)^{\left(10^{10^{10}}\right)}}.}

Notice that alone the number 




10


10

10






{\displaystyle 10^{10^{10}}}

 has 10 billion zeros when written down in decimal notation, and is already by far larger than the number of atoms in the observable universe.
A much more efficient algorithm than Hashiguchi's procedure was devised by Kirsten in 2005. This algorithm runs, for a given nondeterministic finite automaton as input, within double-exponential space. Yet the resource requirements of this algorithm still greatly exceed the margins of what is considered practically feasible.
This algorithm has been optimized and generalized to trees by Colcombet and Löding in 2008 (Colcombet & Löding 2008), as part of the theory of regular cost functions.
It has been implemented in 2017 in the tool suite Stamina.[1]


